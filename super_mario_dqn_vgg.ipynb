{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\utente\\anaconda3\\envs\\va\\lib\\site-packages (2.12.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.15.0-cp310-cp310-win_amd64.whl.metadata (3.6 kB)\n",
      "Collecting tensorflow-intel==2.15.0 (from tensorflow)\n",
      "  Using cached tensorflow_intel-2.15.0-cp310-cp310-win_amd64.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\utente\\anaconda3\\envs\\va\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\utente\\anaconda3\\envs\\va\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\utente\\anaconda3\\envs\\va\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\utente\\anaconda3\\envs\\va\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\utente\\anaconda3\\envs\\va\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\utente\\anaconda3\\envs\\va\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\utente\\anaconda3\\envs\\va\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.0)\n",
      "Collecting ml-dtypes~=0.2.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Using cached ml_dtypes-0.2.0-cp310-cp310-win_amd64.whl.metadata (20 kB)\n",
      "Collecting numpy<2.0.0,>=1.23.5 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading numpy-1.26.2-cp310-cp310-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 0.0/61.2 kB ? eta -:--:--\n",
      "     --------------------------------- ------ 51.2/61.2 kB 1.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 61.2/61.2 kB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\utente\\anaconda3\\envs\\va\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\utente\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading protobuf-4.25.1-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: setuptools in c:\\users\\utente\\anaconda3\\envs\\va\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\utente\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\utente\\anaconda3\\envs\\va\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\utente\\anaconda3\\envs\\va\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.6.2)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\utente\\anaconda3\\envs\\va\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\utente\\anaconda3\\envs\\va\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\utente\\anaconda3\\envs\\va\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.54.2)\n",
      "Collecting tensorboard<2.16,>=2.15 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Using cached tensorboard-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.16,>=2.15.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Using cached keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\utente\\anaconda3\\envs\\va\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\utente\\anaconda3\\envs\\va\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.19.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\utente\\anaconda3\\envs\\va\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\utente\\anaconda3\\envs\\va\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4.3)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading protobuf-4.23.4-cp310-abi3-win_amd64.whl.metadata (540 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\utente\\anaconda3\\envs\\va\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\utente\\anaconda3\\envs\\va\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\utente\\anaconda3\\envs\\va\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.3.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\utente\\anaconda3\\envs\\va\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\utente\\anaconda3\\envs\\va\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\utente\\anaconda3\\envs\\va\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\utente\\anaconda3\\envs\\va\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\utente\\anaconda3\\envs\\va\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\utente\\anaconda3\\envs\\va\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\utente\\anaconda3\\envs\\va\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\utente\\anaconda3\\envs\\va\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\utente\\anaconda3\\envs\\va\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\utente\\anaconda3\\envs\\va\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\utente\\anaconda3\\envs\\va\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n",
      "Using cached tensorflow-2.15.0-cp310-cp310-win_amd64.whl (2.1 kB)\n",
      "Using cached tensorflow_intel-2.15.0-cp310-cp310-win_amd64.whl (300.9 MB)\n",
      "Using cached keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "Using cached ml_dtypes-0.2.0-cp310-cp310-win_amd64.whl (938 kB)\n",
      "Downloading numpy-1.26.2-cp310-cp310-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/15.8 MB 3.3 MB/s eta 0:00:05\n",
      "    --------------------------------------- 0.3/15.8 MB 3.2 MB/s eta 0:00:05\n",
      "    --------------------------------------- 0.4/15.8 MB 3.3 MB/s eta 0:00:05\n",
      "    --------------------------------------- 0.4/15.8 MB 3.3 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.6/15.8 MB 2.9 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.6/15.8 MB 2.9 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.6/15.8 MB 2.9 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.6/15.8 MB 2.9 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.6/15.8 MB 2.9 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.6/15.8 MB 2.9 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.6/15.8 MB 2.9 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.6/15.8 MB 2.9 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.6/15.8 MB 2.9 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.9/15.8 MB 1.4 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 0.9/15.8 MB 1.4 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 0.9/15.8 MB 1.4 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 0.9/15.8 MB 1.4 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 0.9/15.8 MB 1.4 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 0.9/15.8 MB 1.4 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 0.9/15.8 MB 1.4 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 0.9/15.8 MB 1.4 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 0.9/15.8 MB 1.4 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 0.9/15.8 MB 1.4 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 0.9/15.8 MB 1.4 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 0.9/15.8 MB 1.4 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 0.9/15.8 MB 1.4 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 0.9/15.8 MB 1.4 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 1.2/15.8 MB 884.3 kB/s eta 0:00:17\n",
      "   --- ------------------------------------ 1.2/15.8 MB 913.2 kB/s eta 0:00:16\n",
      "   --- ------------------------------------ 1.2/15.8 MB 913.2 kB/s eta 0:00:16\n",
      "   --- ------------------------------------ 1.2/15.8 MB 913.2 kB/s eta 0:00:16\n",
      "   --- ------------------------------------ 1.2/15.8 MB 913.2 kB/s eta 0:00:16\n",
      "   --- ------------------------------------ 1.4/15.8 MB 905.7 kB/s eta 0:00:16\n",
      "   --- ------------------------------------ 1.5/15.8 MB 966.9 kB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 1.8/15.8 MB 1.1 MB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 2.0/15.8 MB 1.2 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 2.2/15.8 MB 1.3 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 2.3/15.8 MB 1.3 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 2.5/15.8 MB 1.4 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 2.6/15.8 MB 1.4 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 2.9/15.8 MB 1.5 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 2.9/15.8 MB 1.5 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 3.0/15.8 MB 1.5 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 3.2/15.8 MB 1.6 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 3.5/15.8 MB 1.7 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 3.6/15.8 MB 1.7 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 4.0/15.8 MB 1.8 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 4.1/15.8 MB 1.8 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 4.4/15.8 MB 1.9 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 4.4/15.8 MB 1.9 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 4.6/15.8 MB 1.9 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 4.8/15.8 MB 2.0 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 5.1/15.8 MB 2.0 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 5.1/15.8 MB 2.1 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 5.4/15.8 MB 2.1 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 5.6/15.8 MB 2.1 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 5.8/15.8 MB 2.2 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 6.0/15.8 MB 2.2 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 6.2/15.8 MB 2.3 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 6.5/15.8 MB 2.3 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 6.6/15.8 MB 2.4 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 6.7/15.8 MB 2.3 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 7.1/15.8 MB 2.4 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 7.3/15.8 MB 2.4 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 7.4/15.8 MB 2.5 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 7.7/15.8 MB 2.5 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 7.8/15.8 MB 2.5 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 7.9/15.8 MB 2.5 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 8.2/15.8 MB 2.5 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 8.3/15.8 MB 2.5 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 8.5/15.8 MB 2.6 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 8.8/15.8 MB 2.6 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 8.9/15.8 MB 2.6 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 9.1/15.8 MB 2.6 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 9.6/15.8 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 9.8/15.8 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 10.1/15.8 MB 2.8 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 10.4/15.8 MB 2.8 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 10.7/15.8 MB 2.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 11.0/15.8 MB 3.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 11.2/15.8 MB 4.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 11.6/15.8 MB 4.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.9/15.8 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 12.3/15.8 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 12.5/15.8 MB 4.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.9/15.8 MB 4.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 13.2/15.8 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.5/15.8 MB 5.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.8/15.8 MB 5.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 14.1/15.8 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.4/15.8 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.6/15.8 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.9/15.8 MB 5.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.2/15.8 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.6/15.8 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.8/15.8 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 5.3 MB/s eta 0:00:00\n",
      "Using cached tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
      "Downloading protobuf-4.23.4-cp310-abi3-win_amd64.whl (422 kB)\n",
      "   ---------------------------------------- 0.0/422.5 kB ? eta -:--:--\n",
      "   -------------- ------------------------- 153.6/422.5 kB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 389.1/422.5 kB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 422.5/422.5 kB 3.8 MB/s eta 0:00:00\n",
      "Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
      "   ---------------------------------------- 0.0/442.0 kB ? eta -:--:--\n",
      "   ---------------------- ----------------- 245.8/442.0 kB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  440.3/442.0 kB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 442.0/442.0 kB 4.6 MB/s eta 0:00:00\n",
      "Installing collected packages: tensorflow-estimator, protobuf, numpy, keras, ml-dtypes, tensorboard, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.12.0\n",
      "    Uninstalling tensorflow-estimator-2.12.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.22.4\n",
      "    Uninstalling numpy-1.22.4:\n",
      "      Successfully uninstalled numpy-1.22.4\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.12.0\n",
      "    Uninstalling keras-2.12.0:\n",
      "      Successfully uninstalled keras-2.12.0\n",
      "  Attempting uninstall: ml-dtypes\n",
      "    Found existing installation: ml-dtypes 0.1.0\n",
      "    Uninstalling ml-dtypes-0.1.0:\n",
      "      Successfully uninstalled ml-dtypes-0.1.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.12.3\n",
      "    Uninstalling tensorboard-2.12.3:\n",
      "      Successfully uninstalled tensorboard-2.12.3\n",
      "  Attempting uninstall: tensorflow-intel\n",
      "    Found existing installation: tensorflow-intel 2.12.0\n",
      "    Uninstalling tensorflow-intel-2.12.0:\n",
      "      Successfully uninstalled tensorflow-intel-2.12.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.12.0\n",
      "    Uninstalling tensorflow-2.12.0:\n",
      "      Successfully uninstalled tensorflow-2.12.0\n",
      "Successfully installed keras-2.15.0 ml-dtypes-0.2.0 numpy-1.26.2 protobuf-4.23.4 tensorboard-2.15.1 tensorflow-2.15.0 tensorflow-estimator-2.15.0 tensorflow-intel-2.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\UTENTE\\anaconda3\\envs\\va\\Lib\\site-packages\\~ensorflow'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "stable-baselines3 1.6.0 requires gym==0.21, but you have gym 0.26.2 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _pywrap_tfe: Impossibile trovare la procedura specificata.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m resize\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvgg16\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VGG16\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m image\n",
      "File \u001b[1;32mc:\\Users\\UTENTE\\anaconda3\\envs\\va\\lib\\site-packages\\keras\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n",
      "File \u001b[1;32mc:\\Users\\UTENTE\\anaconda3\\envs\\va\\lib\\site-packages\\keras\\__internal__\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m losses\n",
      "File \u001b[1;32mc:\\Users\\UTENTE\\anaconda3\\envs\\va\\lib\\site-packages\\keras\\__internal__\\backend\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _initialize_variables \u001b[38;5;28;01mas\u001b[39;00m initialize_variables\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m track_variable\n",
      "File \u001b[1;32mc:\\Users\\UTENTE\\anaconda3\\envs\\va\\lib\\site-packages\\keras\\src\\__init__.py:21\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n",
      "File \u001b[1;32mc:\\Users\\UTENTE\\anaconda3\\envs\\va\\lib\\site-packages\\keras\\src\\applications\\__init__.py:18\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Keras Applications are premade architectures with pre-trained weights.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConvNeXtBase\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConvNeXtLarge\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConvNeXtSmall\n",
      "File \u001b[1;32mc:\\Users\\UTENTE\\anaconda3\\envs\\va\\lib\\site-packages\\keras\\src\\applications\\convnext.py:26\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m\"\"\"ConvNeXt models for Keras.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03mReferences:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124;03m  (CVPR 2022)\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m initializers\n",
      "File \u001b[1;32mc:\\Users\\UTENTE\\anaconda3\\envs\\va\\lib\\site-packages\\tensorflow\\__init__.py:48\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[0;32m     46\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[1;32m---> 48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "File \u001b[1;32mc:\\Users\\UTENTE\\anaconda3\\envs\\va\\lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dispatch\n",
      "File \u001b[1;32mc:\\Users\\UTENTE\\anaconda3\\envs\\va\\lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\autograph\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mag_ctx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_convert \u001b[38;5;66;03m# line: 493\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\UTENTE\\anaconda3\\envs\\va\\lib\\site-packages\\tensorflow\\python\\autograph\\core\\ag_ctx.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[0;32m     25\u001b[0m stacks \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mlocal()\n",
      "File \u001b[1;32mc:\\Users\\UTENTE\\anaconda3\\envs\\va\\lib\\site-packages\\tensorflow\\python\\autograph\\utils\\__init__.py:17\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext_managers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor_list\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n",
      "File \u001b[1;32mc:\\Users\\UTENTE\\anaconda3\\envs\\va\\lib\\site-packages\\tensorflow\\python\\autograph\\utils\\context_managers.py:19\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Various context managers.\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcontextlib\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontrol_dependency_on_returns\u001b[39m(return_value):\n",
      "File \u001b[1;32mc:\\Users\\UTENTE\\anaconda3\\envs\\va\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:41\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# pywrap_tensorflow must be imported first to avoid protobuf issues.\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# (b/143110113)\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# pylint: disable=invalid-import-order,g-bad-import-order,unused-import\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow\n\u001b[1;32m---> 41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tfe\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# pylint: enable=invalid-import-order,g-bad-import-order,unused-import\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2\n",
      "File \u001b[1;32mc:\\Users\\UTENTE\\anaconda3\\envs\\va\\lib\\site-packages\\tensorflow\\python\\pywrap_tfe.py:25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pywrap_tfe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _pywrap_tfe: Impossibile trovare la procedura specificata."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "import gym\n",
    "import gym_super_mario_bros\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT, COMPLEX_MOVEMENT\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from tqdm import tqdm\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import gym_pull\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gym_pull' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgym_pull\u001b[49m\u001b[38;5;241m.\u001b[39mpull(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgithub.com/ppaquette/gym-super-mario\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gym_pull' is not defined"
     ]
    }
   ],
   "source": [
    "gym_pull.pull('github.com/ppaquette/gym-super-mario')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UTENTE\\anaconda3\\envs\\va\\lib\\site-packages\\gym\\envs\\registration.py:592: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'render_modes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mgym_super_mario_bros\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSuperMarioBros-v0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapply_api_compatibility\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrender_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhuman\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m env \u001b[38;5;241m=\u001b[39m JoypadSpace(env, COMPLEX_MOVEMENT)\n",
      "File \u001b[1;32mc:\\Users\\UTENTE\\anaconda3\\envs\\va\\lib\\site-packages\\gym\\envs\\registration.py:625\u001b[0m, in \u001b[0;36mmake\u001b[1;34m(id, max_episode_steps, autoreset, new_step_api, disable_env_checker, **kwargs)\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;66;03m# If we have access to metadata we check that \"render_mode\" is valid\u001b[39;00m\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(env_creator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 625\u001b[0m     render_modes \u001b[38;5;241m=\u001b[39m \u001b[43menv_creator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrender_modes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;66;03m# We might be able to fall back to the HumanRendering wrapper if 'human' rendering is not supported natively\u001b[39;00m\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    629\u001b[0m         mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    630\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m render_modes\n\u001b[0;32m    631\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle_rgb_array\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m render_modes \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb_array\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m render_modes)\n\u001b[0;32m    632\u001b[0m     ):\n",
      "\u001b[1;31mKeyError\u001b[0m: 'render_modes'"
     ]
    }
   ],
   "source": [
    "env = gym_super_mario_bros.make('SuperMarioBros-v0', apply_api_compatibility=True, render_mode=\"human\")\n",
    "env = JoypadSpace(env, COMPLEX_MOVEMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_frame(frame, new_size=(42,42), to_gray=True):\n",
    "    if to_gray:\n",
    "        return resize(frame, new_size, anti_aliasing=True).max(axis=2)\n",
    "    else:\n",
    "        return resize(frame, new_size, anti_aliasing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def prepare_state(state):\n",
    "    return torch.from_numpy(preprocess_frame(state, to_gray=True)).float().unsqueeze(0)\n",
    "\n",
    "def prepare_multi_states(state1, state2):\n",
    "    state1 = state1.clone()\n",
    "    temp = torch.from_numpy(preprocess_frame(state2, to_gray=True)).float()\n",
    "    state1[0][0] = state1[0][1]\n",
    "    state1[0][1] = state1[0][2]\n",
    "    state1[0][2] = temp\n",
    "    return state1\n",
    "\n",
    "def prepare_initial_state(state, N=4):\n",
    "    state_ = torch.from_numpy(preprocess_frame(state, to_gray=True)).float()\n",
    "    tmp = state_.repeat((N, 1, 1))\n",
    "    return tmp.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policy definition\n",
    "\n",
    "def policy(qvalues, eps=None):\n",
    "    if eps is not None:\n",
    "        if torch.rand(1) < eps:\n",
    "            return torch.randint(low=0, high=qvalues.shape[1], size=(1,))\n",
    "        else:\n",
    "            return torch.argmax(qvalues)\n",
    "    else:\n",
    "        return torch.multinomial(F.softmax(F.normalize(qvalues)), num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experience replay memory in order to sample mini batches of experiences for training\n",
    "from random import shuffle\n",
    "\n",
    "class ExperienceReplayMemory:\n",
    "    def __init__(self, N=500, batch_size=100):\n",
    "        self.N = N\n",
    "        self.batch_size = batch_size\n",
    "        self.memory = []\n",
    "        self.counter = 0\n",
    "\n",
    "    def add_memory(self, state1, action, reward, state2):\n",
    "        self.counter += 1\n",
    "        if self.counter % self.N == 0:\n",
    "            self.shuffle_memory()\n",
    "        if(len(self.memory) < self.N):\n",
    "            self.memory.append((state1, action, reward, state2))\n",
    "        else:\n",
    "            rand_idx = np.random.randint(0, self.N - 1)\n",
    "            self.memory[rand_idx] = (state1, action, reward, state2)\n",
    "\n",
    "    def shuffle_memory(self):\n",
    "        shuffle(self.memory)\n",
    "\n",
    "    def get_batch(self):\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            batch_size = len(self.memory)\n",
    "        else:\n",
    "            batch_size = self.batch_size\n",
    "        if len(self.memory) < 1:\n",
    "            print(\"Error: Memory is empty\")\n",
    "            return None\n",
    "        \n",
    "        ind = np.random.choice(np.arange(len(self.memory)), batch_size, replace=False)\n",
    "        batch = [self.memory[i] for i in ind]\n",
    "        state1_batch = torch.stack([x[0].squeeze(0) for x in batch], dim=0)\n",
    "        state1_batch.to(device)\n",
    "        action_batch = torch.Tensor([x[1] for x in batch]).long()\n",
    "        action_batch.to(device)\n",
    "        reward_batch = torch.Tensor([x[2] for x in batch])\n",
    "        reward_batch.to(device)\n",
    "        state2_batch = torch.stack([x[3].squeeze(0) for x in batch], dim=0)\n",
    "        state2_batch.to(device)\n",
    "        return state1_batch, action_batch, reward_batch, state2_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intrinsic curiosity module: 3 diverse nn networks (forward, inverse, encoder)\n",
    "\n",
    "class Phi(nn.Module): # Encoder\n",
    "    def __init__(self):\n",
    "        super(Phi, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(4, 32, kernel_size=(3,3), stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=(3,3), stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=(3,3), stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(32, 32, kernel_size=(3,3), stride=2, padding=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.normalize(x)\n",
    "        y = F.elu(self.conv1(x))\n",
    "        y = F.elu(self.conv2(y))\n",
    "        y = F.elu(self.conv3(y))\n",
    "        y = F.elu(self.conv4(y))\n",
    "        y = y.flatten(start_dim=1)\n",
    "        return y\n",
    "    \n",
    "class Gnet(nn.Module): # Inverse model\n",
    "    def __init__(self):\n",
    "        super(Gnet, self).__init__()\n",
    "        self.fc1 = nn.Linear(576, 256)\n",
    "        self.fc2 = nn.Linear(256, env.action_space.n)\n",
    "\n",
    "    def forward(self, state1, state2):\n",
    "        x = torch.cat((state1, state2), dim=1)\n",
    "        y = F.relu(self.fc1(x))\n",
    "        y = self.fc2(y)\n",
    "        y = F.softmax(y, dim=1)\n",
    "        return y\n",
    "    \n",
    "class Fnet(nn.Module): # Forward model\n",
    "    def __init__(self):\n",
    "        super(Fnet, self).__init__()\n",
    "        self.fc1 = nn.Linear(300, 256)\n",
    "        self.fc2 = nn.Linear(256, 288)\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        action_ = torch.zeros((action.shape[0], env.action_space.n)).cuda()\n",
    "        indices = torch.stack((torch.arange(action.shape[0]).cuda(), action.squeeze().cuda()), dim=0).cuda()\n",
    "        indices = indices.tolist()\n",
    "        action_[indices] = 1\n",
    "        x = torch.cat((state, action_), dim=1)\n",
    "        y = F.relu(self.fc1(x))\n",
    "        y = self.fc2(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q network\n",
    "\n",
    "class Qnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Qnet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=4, out_channels=32, kernel_size=(3,3), stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3,3), stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3,3), stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3,3), stride=2, padding=1)\n",
    "        self.fc1 = nn.Linear(288, 100)\n",
    "        self.fc2 = nn.Linear(100, env.action_space.n)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.normalize(x)\n",
    "        y = F.elu(self.conv1(x))\n",
    "        y = F.elu(self.conv2(y))\n",
    "        y = F.elu(self.conv3(y))\n",
    "        y = F.elu(self.conv4(y))\n",
    "        y = y.flatten(start_dim=2)\n",
    "        y = y.view(y.shape[0], -1, 32)\n",
    "        y = y.flatten(start_dim=1)\n",
    "        y = F.elu(self.fc1(y))\n",
    "        y = self.fc2(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "hyperparams = {\n",
    "    'batch_size': 256, # from 32 to 512\n",
    "    'beta': 0.2,\n",
    "    'lambda': 0.1,\n",
    "    'eta': 1.0,\n",
    "    'gamma': 0.2,\n",
    "    'max_episode_length': 200,\n",
    "    'min_progress': 15,\n",
    "    'action_repeats': 6,\n",
    "    'frames_per_state': 4,\n",
    "    'learning_rate': 0.001,\n",
    "    'skip_frames': 4\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(q_loss, forward_loss, inverse_loss, beta, lambda_value):\n",
    "    loss_ = (1 - beta)*inverse_loss\n",
    "    loss_ += hyperparams['beta']*forward_loss\n",
    "    loss_ = loss_.sum() / loss_.flatten().shape[0]\n",
    "    loss_ += lambda_value*q_loss\n",
    "    return loss_\n",
    "\n",
    "def reset_env():\n",
    "    env.reset()\n",
    "    state1 = prepare_initial_state(env.render(mode='rgb_array'))\n",
    "    return state1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qnet = Qnet()\n",
    "encoder = Phi()\n",
    "forward_model = Fnet()\n",
    "inverse_model = Gnet()\n",
    "forward_loss = nn.MSELoss(reduction='none')\n",
    "inverse_loss = nn.CrossEntropyLoss(reduction='none')\n",
    "qloss = nn.MSELoss()\n",
    "all_model_params = list(qnet.parameters()) + list(encoder.parameters()) + list(forward_model.parameters()) + list(inverse_model.parameters())\n",
    "\n",
    "if device == 'cuda':\n",
    "    qnet.cuda()\n",
    "    encoder.cuda()\n",
    "    forward_model.cuda()\n",
    "    inverse_model.cuda()\n",
    "    forward_loss.cuda()\n",
    "    inverse_loss.cuda()\n",
    "    qloss.cuda()\n",
    "    all_model_params = list(qnet.parameters()) + list(encoder.parameters()) + list(forward_model.parameters()) + list(inverse_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICM(state1, action, state2, forward_scale = 1., inverse_scale = 1e4):\n",
    "    state1_hat = encoder(state1.cuda())\n",
    "    state2_hat = encoder(state2.cuda())\n",
    "    state2_hat_pred = forward_model(state1_hat.detach(), action.detach())\n",
    "    forward_pred_err = forward_scale * forward_loss(state2_hat_pred, state2_hat.detach()).sum(dim=1).unsqueeze(dim=1)\n",
    "    pred_action = inverse_model(state1_hat, state2_hat)\n",
    "    inverse_pred_err = inverse_scale * inverse_loss(pred_action, action.detach().flatten()).unsqueeze(dim=1)\n",
    "    return forward_pred_err, inverse_pred_err\n",
    "\n",
    "def minibatch_train(use_explicit=True, gamma = hyperparams['gamma']):\n",
    "    state1_batch, action_batch, reward_batch, state2_batch = replay.get_batch()\n",
    "    action_batch = action_batch.view(action_batch.shape[0], 1)\n",
    "    reward_batch = reward_batch.view(reward_batch.shape[0], 1)\n",
    "    forward_pred_err, inverse_pred_err = ICM(state1_batch.cuda(), action_batch.cuda(), state2_batch)\n",
    "    i_reward = (1./hyperparams['eta'])*forward_pred_err \n",
    "    reward = i_reward.detach() \n",
    "    if use_explicit:\n",
    "        reward += reward_batch\n",
    "    qvals = qnet(state2_batch.cuda())\n",
    "    reward += gamma*torch.max(qvals)\n",
    "    reward_pred = qnet(state1_batch.cuda()) \n",
    "    reward_target = reward_pred.clone()\n",
    "    indices = torch.stack((torch.arange(action_batch.shape[0]), action_batch.squeeze()), dim=0).cuda()\n",
    "    indices = indices.tolist()\n",
    "    reward_target[indices] = reward.squeeze()\n",
    "    q_loss = 1e5 * qloss(F.normalize(reward_pred), F.normalize(reward_target.detach()))\n",
    "    return forward_pred_err, inverse_pred_err, q_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = VGG16(weights='imagenet', include_top=False, \n",
    "              pooling='max', input_shape=(160, 240, 3))\n",
    "\n",
    "# print the summary of the model's architecture.\n",
    "vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_layer in vgg16.layers:\n",
    "  model_layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_embeddings(object_image : image):\n",
    "    \n",
    "    \"\"\"\n",
    "      -----------------------------------------------------\n",
    "      convert image into 3d array and add additional dimension for model input\n",
    "      -----------------------------------------------------\n",
    "      return embeddings of the given image\n",
    "    \"\"\"\n",
    "\n",
    "    image_array = np.expand_dims(image.img_to_array(object_image), axis = 0)\n",
    "    image_embedding = vgg16.predict(image_array)\n",
    "\n",
    "    return image_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_score(first_image : str, second_image : str):\n",
    "    \"\"\"\n",
    "        -----------------------------------------------------\n",
    "        Takes image array and computes its embedding using VGG16 model.\n",
    "        -----------------------------------------------------\n",
    "        return embedding of the image\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    first_image_vector = get_image_embeddings(first_image)\n",
    "    second_image_vector = get_image_embeddings(second_image)\n",
    "    \n",
    "    similarity_score = cosine_similarity(first_image_vector, second_image_vector).reshape(1,)\n",
    "\n",
    "    return similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, lambda_value=hyperparams['lambda'], beta=hyperparams['beta'], gamma=hyperparams['gamma'], eps = 0.15, batch_size=None):\n",
    "    env.reset()\n",
    "    state1_vgg = env.render(mode='rgb_array')\n",
    "    state1 = prepare_initial_state(state1_vgg)\n",
    "    state1.to(device)\n",
    "    eps = eps\n",
    "    losses = []\n",
    "    episode_length = 0\n",
    "    switch_to_eps_greedy = 1000\n",
    "    state_deque = deque(maxlen=hyperparams['frames_per_state'])\n",
    "    env.reset()\n",
    "    _, _, _,info_0 = env.step(0)\n",
    "    env.reset()\n",
    "    last_x_pos = info_0['x_pos']\n",
    "    e_reward = 0\n",
    "    ep_lengths = []\n",
    "    #use_explicit = False\n",
    "    for i in tqdm(range(epochs)):\n",
    "        optimizer.zero_grad()\n",
    "        episode_length += 1\n",
    "        q_val_pred = qnet(state1.cuda())\n",
    "        if i > switch_to_eps_greedy:\n",
    "            action = int(policy(q_val_pred, eps))\n",
    "        else:\n",
    "            action = int(policy(q_val_pred))\n",
    "        for j in range(hyperparams['action_repeats']):\n",
    "            for k in range(hyperparams['skip_frames']):\n",
    "                state2, e_reward_, done, info = env.step(action)\n",
    "                if get_similarity_score(state1_vgg, state2) < 0.8:\n",
    "                    e_reward_ = e_reward_ + 1\n",
    "                    print(\"exploration reward added\")\n",
    "                e_reward += e_reward_\n",
    "                if done:\n",
    "                    state1 = reset_env()\n",
    "                    break \n",
    "            state_deque.append(prepare_state(state2))\n",
    "        state2 = torch.stack(list(state_deque), dim=1)\n",
    "        replay.add_memory(state1, action, e_reward, state2)\n",
    "        e_reward = 0\n",
    "        if episode_length > hyperparams['max_episode_length']:\n",
    "            if (info['x_pos'] - last_x_pos) < hyperparams['min_progress']:\n",
    "                done = True\n",
    "            else:\n",
    "                last_x_pos = info['x_pos']\n",
    "        if done:\n",
    "            ep_lengths.append(episode_length)\n",
    "            episode_length = 0\n",
    "            state1 = reset_env()\n",
    "            last_x_pos = info_0['x_pos']\n",
    "        else:\n",
    "            state1 = state2\n",
    "        if len(replay.memory) < batch_size:\n",
    "            continue\n",
    "        forward_pred_err, inverse_pred_err, q_loss = minibatch_train(use_explicit = False, gamma=gamma)\n",
    "        loss = loss_fn(q_loss, forward_pred_err, inverse_pred_err, lambda_value=lambda_value, beta=beta)\n",
    "        loss_list = (q_loss.mean(), forward_pred_err.flatten().mean(), inverse_pred_err.flatten().mean())\n",
    "        losses.append(loss_list)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return ep_lengths, losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay = ExperienceReplayMemory(N=1500, batch_size=hyperparams['batch_size'])\n",
    "optimizer = optim.Adam(all_model_params, lr=hyperparams['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_len, losses_plot =train(epochs=100, lambda_value=hyperparams['lambda'], beta=hyperparams['beta'], gamma=hyperparams['gamma'], eps = 0.15)\n",
    "losses_q = [x[0].detach().numpy() for x in losses_plot]\n",
    "losses_f = [x[1].detach().numpy() for x in losses_plot]\n",
    "losses_i = [x[2].detach().numpy() for x in losses_plot]\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(np.log(losses_q), label='Q loss')\n",
    "plt.plot(np.log(losses_f), label='Forward loss')\n",
    "plt.plot(np.log(losses_i), label='Inverse loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.1\n",
    "done = True\n",
    "state_deque = deque(maxlen=hyperparams['frames_per_state'])\n",
    "for step in range(5000):\n",
    "    if done: \n",
    "        env.reset()\n",
    "        state1 = prepare_initial_state(env.render(mode='rgb_array'))\n",
    "    q_val_pred = qnet(state1)\n",
    "    action = int(policy(q_val_pred, eps))\n",
    "    state2, reward, done, info = env.step(action)\n",
    "    state2 = prepare_multi_states(state1, state2)\n",
    "    state1 = state2\n",
    "    env.render()\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "va",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
